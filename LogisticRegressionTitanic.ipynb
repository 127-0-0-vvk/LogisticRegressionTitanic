{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegressionTitanic.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/127-0-0-vvk/LogisticRegressionTitanic/blob/main/LogisticRegressionTitanic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure you download the file Titanic-train.csv to your google\n",
        "# drive. This code should be able to access it if it is there! Place the file at\n",
        "# the top level directory of google drive\n",
        "from google.colab import drive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Make sure file is listed - this code should show it \n",
        "listed = drive.ListFile({'q': \"title contains 'titanic_train.csv'\"}).GetList()\n",
        "print (\"fetching csv files...\")\n",
        "for file in listed:\n",
        "  print('title {}, id {}'.format(file['title'], file['id']))\n",
        "\n",
        "%pwd\n",
        "print('listing content')\n",
        "%ls /content/drive\n"
      ],
      "metadata": {
        "id": "Wu5PlwW1LAT7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd23a03-c4d6-4143-c656-fa5dadda63a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "fetching csv files...\n",
            "listing content\n",
            "\u001b[0m\u001b[01;34mMyDrive\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DQyecb0LcN6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRkbl8wMGNxd"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "#Import the data set\n",
        "titanic_data = pd.read_csv('/content/titanic_train.csv')\n",
        "#\n",
        "#Exploratory data analysis\n",
        "sns.heatmap(titanic_data.isnull(), cbar=False)\n",
        "sns.countplot(x='Survived', data=titanic_data)\n",
        "sns.countplot(x='Survived', hue='Sex', data=titanic_data)\n",
        "sns.countplot(x='Survived', hue='Pclass', data=titanic_data)\n",
        "plt.hist(titanic_data['Age'].dropna())\n",
        "plt.hist(titanic_data['Fare'])\n",
        "sns.boxplot(titanic_data['Pclass'], titanic_data['Age'])\n",
        "\n",
        "#Imputation function\n",
        "def impute_missing_age(columns):\n",
        "    age = columns[0]\n",
        "    passenger_class = columns[1]\n",
        "    \n",
        "    if pd.isnull(age):\n",
        "        if(passenger_class == 1):\n",
        "            return titanic_data[titanic_data['Pclass'] == 1]['Age'].mean()\n",
        "        elif(passenger_class == 2):\n",
        "            return titanic_data[titanic_data['Pclass'] == 2]['Age'].mean()\n",
        "        elif(passenger_class == 3):\n",
        "            return titanic_data[titanic_data['Pclass'] == 3]['Age'].mean()\n",
        "        \n",
        "    else:\n",
        "        return age\n",
        "\n",
        "#Impute the missing Age data\n",
        "titanic_data['Age'] = titanic_data[['Age', 'Pclass']].apply(impute_missing_age, axis = 1)\n",
        "\n",
        "#Reinvestigate missing data\n",
        "sns.heatmap(titanic_data.isnull(), cbar=False)\n",
        "\n",
        "#Drop null data\n",
        "titanic_data.drop('Cabin', axis=1, inplace = True)\n",
        "titanic_data.dropna(inplace = True)\n",
        "\n",
        "#Create dummy variables for Sex and Embarked columns\n",
        "sex_data = pd.get_dummies(titanic_data['Sex'], drop_first = True)\n",
        "embarked_data = pd.get_dummies(titanic_data['Embarked'], drop_first = True)\n",
        "\n",
        "#Add dummy variables to the DataFrame and drop non-numeric data\n",
        "titanic_data = pd.concat([titanic_data, sex_data, embarked_data], axis = 1)\n",
        "titanic_data.drop(['Name', 'PassengerId', 'Ticket', 'Sex', 'Embarked'], axis = 1, inplace = True)\n",
        "\n",
        "#Print the finalized data set\n",
        "print(titanic_data.head())\n",
        "\n",
        "#Split the data set into x and y data\n",
        "y_data = titanic_data['Survived']\n",
        "x_data = titanic_data.drop('Survived', axis = 1)\n",
        "\n",
        "#Split the data set into training data and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x_data, y_data, test_size = 0.3)\n",
        "\n",
        "#Create the model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "\n",
        "#Train the model and create predictions\n",
        "model.fit(x_training_data, y_training_data)\n",
        "predictions = model.predict(x_test_data)\n",
        "\n",
        "#Calculate performance metrics\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test_data, predictions))\n",
        "\n",
        "#Generate a confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print('*******confusion matrix below*******')\n",
        "print(confusion_matrix(y_test_data, predictions))"
      ]
    }
  ]
}